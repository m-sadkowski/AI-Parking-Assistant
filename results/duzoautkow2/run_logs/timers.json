{
    "name": "root",
    "gauges": {
        "AgentControl.Policy.Entropy.mean": {
            "value": 2.039346218109131,
            "min": 1.419320821762085,
            "max": 2.039346218109131,
            "count": 270
        },
        "AgentControl.Policy.Entropy.sum": {
            "value": 20373.068359375,
            "min": 13233.55859375,
            "max": 20485.7890625,
            "count": 270
        },
        "AgentControl.Step.mean": {
            "value": 2699985.0,
            "min": 9875.0,
            "max": 2699985.0,
            "count": 270
        },
        "AgentControl.Step.sum": {
            "value": 2699985.0,
            "min": 9875.0,
            "max": 2699985.0,
            "count": 270
        },
        "AgentControl.Policy.ExtrinsicValueEstimate.mean": {
            "value": 1.3125367164611816,
            "min": -3.349302291870117,
            "max": 1.3689805269241333,
            "count": 270
        },
        "AgentControl.Policy.ExtrinsicValueEstimate.sum": {
            "value": 429.19952392578125,
            "min": -284.6907043457031,
            "max": 453.78839111328125,
            "count": 270
        },
        "AgentControl.Losses.PolicyLoss.mean": {
            "value": 0.0300047901389189,
            "min": 0.02077442743582651,
            "max": 0.04156271017200197,
            "count": 270
        },
        "AgentControl.Losses.PolicyLoss.sum": {
            "value": 0.1500239506945945,
            "min": 0.10260474884998985,
            "max": 0.19455456269497517,
            "count": 270
        },
        "AgentControl.Losses.ValueLoss.mean": {
            "value": 0.09516412470489741,
            "min": 0.01201860135886818,
            "max": 16.643431901931763,
            "count": 270
        },
        "AgentControl.Losses.ValueLoss.sum": {
            "value": 0.47582062352448706,
            "min": 0.05793422495480627,
            "max": 66.57372760772705,
            "count": 270
        },
        "AgentControl.Policy.LearningRate.mean": {
            "value": 7.305450294552401e-05,
            "min": 7.305450294552401e-05,
            "max": 9.994281755718252e-05,
            "count": 270
        },
        "AgentControl.Policy.LearningRate.sum": {
            "value": 0.00036527251472762005,
            "min": 0.00029300131699879,
            "max": 0.00049922731077269,
            "count": 270
        },
        "AgentControl.Policy.Epsilon.mean": {
            "value": 0.17305447599999998,
            "min": 0.17305447599999998,
            "max": 0.1999428175,
            "count": 270
        },
        "AgentControl.Policy.Epsilon.sum": {
            "value": 0.86527238,
            "min": 0.69300121,
            "max": 0.99922731,
            "count": 270
        },
        "AgentControl.Policy.Beta.mean": {
            "value": 0.0219190373524,
            "min": 0.0219190373524,
            "max": 0.02998285096825,
            "count": 270
        },
        "AgentControl.Policy.Beta.sum": {
            "value": 0.109595186762,
            "min": 0.087911062879,
            "max": 0.149768270269,
            "count": 270
        },
        "AgentControl.Environment.EpisodeLength.mean": {
            "value": 29.559633027522935,
            "min": 27.524216524216524,
            "max": 981.8461538461538,
            "count": 270
        },
        "AgentControl.Environment.EpisodeLength.sum": {
            "value": 9666.0,
            "min": 3340.0,
            "max": 13295.0,
            "count": 270
        },
        "AgentControl.Environment.CumulativeReward.mean": {
            "value": 2.7283237926456905,
            "min": -103.07920111502919,
            "max": 2.9089116307493215,
            "count": 270
        },
        "AgentControl.Environment.CumulativeReward.sum": {
            "value": 892.1618801951408,
            "min": -1585.9707421660423,
            "max": 958.735513150692,
            "count": 270
        },
        "AgentControl.Policy.ExtrinsicReward.mean": {
            "value": 2.7283237926456905,
            "min": -103.07920111502919,
            "max": 2.9089116307493215,
            "count": 270
        },
        "AgentControl.Policy.ExtrinsicReward.sum": {
            "value": 892.1618801951408,
            "min": -1585.9707421660423,
            "max": 958.735513150692,
            "count": 270
        },
        "AgentControl.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 270
        },
        "AgentControl.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 270
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1748288435",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Michal\\Documents\\GitHub\\AI-Parking-Assistant\\venv\\Scripts\\mlagents-learn config/moveToGoal.yaml --run-id=duzoautkow2",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.7.0+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1748291456"
    },
    "total": 3021.1317601,
    "count": 1,
    "self": 0.0061699000002590765,
    "children": {
        "run_training.setup": {
            "total": 0.21064430000000023,
            "count": 1,
            "self": 0.21064430000000023
        },
        "TrainerController.start_learning": {
            "total": 3020.9149459,
            "count": 1,
            "self": 4.345512800023698,
            "children": {
                "TrainerController._reset_env": {
                    "total": 9.1590606,
                    "count": 1,
                    "self": 9.1590606
                },
                "TrainerController.advance": {
                    "total": 3007.3294937999763,
                    "count": 205353,
                    "self": 3.868558299993765,
                    "children": {
                        "env_step": {
                            "total": 1754.963637900037,
                            "count": 205353,
                            "self": 1603.3610028001476,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 148.98191559993325,
                                    "count": 205353,
                                    "self": 10.302719999945282,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 138.67919559998796,
                                            "count": 150087,
                                            "self": 138.67919559998796
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.6207194999561256,
                                    "count": 205352,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 3003.6787035999873,
                                            "count": 205352,
                                            "is_parallel": true,
                                            "self": 1647.1154379000595,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0005222999999991984,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00011759999999938486,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00040469999999981354,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.00040469999999981354
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1356.5627433999277,
                                                    "count": 205352,
                                                    "is_parallel": true,
                                                    "self": 31.98267579993808,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 38.822671200045825,
                                                            "count": 205352,
                                                            "is_parallel": true,
                                                            "self": 38.822671200045825
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1214.096414399884,
                                                            "count": 205352,
                                                            "is_parallel": true,
                                                            "self": 1214.096414399884
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 71.66098200005997,
                                                            "count": 205352,
                                                            "is_parallel": true,
                                                            "self": 21.20384550025051,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 50.457136499809465,
                                                                    "count": 821408,
                                                                    "is_parallel": true,
                                                                    "self": 50.457136499809465
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1248.4972975999456,
                            "count": 205352,
                            "self": 5.575474699942106,
                            "children": {
                                "process_trajectory": {
                                    "total": 306.0973815000034,
                                    "count": 205352,
                                    "self": 305.7734512000036,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.3239302999998017,
                                            "count": 5,
                                            "self": 0.3239302999998017
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 936.8244414,
                                    "count": 1302,
                                    "self": 619.2247112999944,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 317.59973010000556,
                                            "count": 26040,
                                            "self": 317.59973010000556
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 9.99999883788405e-07,
                    "count": 1,
                    "self": 9.99999883788405e-07
                },
                "TrainerController._save_models": {
                    "total": 0.080877700000201,
                    "count": 1,
                    "self": 0.011882499999956053,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.06899520000024495,
                            "count": 1,
                            "self": 0.06899520000024495
                        }
                    }
                }
            }
        }
    }
}