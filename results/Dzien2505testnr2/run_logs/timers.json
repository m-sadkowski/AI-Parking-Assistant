{
    "name": "root",
    "gauges": {
        "AgentControl.Policy.Entropy.mean": {
            "value": 1.7477444410324097,
            "min": 1.4205127954483032,
            "max": 1.7477444410324097,
            "count": 136
        },
        "AgentControl.Policy.Entropy.sum": {
            "value": 17491.42578125,
            "min": 14201.623046875,
            "max": 17702.474609375,
            "count": 136
        },
        "AgentControl.Step.mean": {
            "value": 1359974.0,
            "min": 9999.0,
            "max": 1359974.0,
            "count": 136
        },
        "AgentControl.Step.sum": {
            "value": 1359974.0,
            "min": 9999.0,
            "max": 1359974.0,
            "count": 136
        },
        "AgentControl.Policy.ExtrinsicValueEstimate.mean": {
            "value": 5.605155944824219,
            "min": 0.11903156340122223,
            "max": 5.77349328994751,
            "count": 136
        },
        "AgentControl.Policy.ExtrinsicValueEstimate.sum": {
            "value": 459.6227722167969,
            "min": 9.641556739807129,
            "max": 466.4172058105469,
            "count": 136
        },
        "AgentControl.Losses.PolicyLoss.mean": {
            "value": 0.029805468960548753,
            "min": 0.023750243672766375,
            "max": 0.03947406601409966,
            "count": 136
        },
        "AgentControl.Losses.PolicyLoss.sum": {
            "value": 0.14902734480274377,
            "min": 0.09553681862985286,
            "max": 0.18483099437435158,
            "count": 136
        },
        "AgentControl.Losses.ValueLoss.mean": {
            "value": 0.038482189313508566,
            "min": 0.0012375447069643997,
            "max": 0.18604926977306604,
            "count": 136
        },
        "AgentControl.Losses.ValueLoss.sum": {
            "value": 0.19241094656754285,
            "min": 0.004950178827857599,
            "max": 0.9302463488653302,
            "count": 136
        },
        "AgentControl.Policy.LearningRate.mean": {
            "value": 8.645644954356401e-05,
            "min": 8.645644954356401e-05,
            "max": 9.994395755604252e-05,
            "count": 136
        },
        "AgentControl.Policy.LearningRate.sum": {
            "value": 0.00043228224771782003,
            "min": 0.00034620786379218997,
            "max": 0.0004992228907771101,
            "count": 136
        },
        "AgentControl.Policy.Epsilon.mean": {
            "value": 0.186456436,
            "min": 0.186456436,
            "max": 0.1999439575,
            "count": 136
        },
        "AgentControl.Policy.Epsilon.sum": {
            "value": 0.93228218,
            "min": 0.74620781,
            "max": 0.99922289,
            "count": 136
        },
        "AgentControl.Policy.Beta.mean": {
            "value": 0.0259382851564,
            "min": 0.0259382851564,
            "max": 0.02998319285425,
            "count": 136
        },
        "AgentControl.Policy.Beta.sum": {
            "value": 0.129691425782,
            "min": 0.10386772221899998,
            "max": 0.149766944711,
            "count": 136
        },
        "AgentControl.Environment.EpisodeLength.mean": {
            "value": 834.5833333333334,
            "min": 607.6875,
            "max": 999.0,
            "count": 136
        },
        "AgentControl.Environment.EpisodeLength.sum": {
            "value": 10015.0,
            "min": 7557.0,
            "max": 13858.0,
            "count": 136
        },
        "AgentControl.Environment.CumulativeReward.mean": {
            "value": 49.1063519368569,
            "min": -10.884926904737949,
            "max": 58.571653842926025,
            "count": 136
        },
        "AgentControl.Environment.CumulativeReward.sum": {
            "value": 589.2762232422829,
            "min": -108.8492690473795,
            "max": 657.8829833269119,
            "count": 136
        },
        "AgentControl.Policy.ExtrinsicReward.mean": {
            "value": 49.1063519368569,
            "min": -10.884926904737949,
            "max": 58.571653842926025,
            "count": 136
        },
        "AgentControl.Policy.ExtrinsicReward.sum": {
            "value": 589.2762232422829,
            "min": -108.8492690473795,
            "max": 657.8829833269119,
            "count": 136
        },
        "AgentControl.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 136
        },
        "AgentControl.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 136
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1748203824",
        "python_version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\AI-Parking-Assistant\\venv\\Scripts\\mlagents-learn config/moveToGoal.yaml --run-id=Dzien2505testnr2",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.7.0+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1748205702"
    },
    "total": 1878.5663687,
    "count": 1,
    "self": 0.004916200000025128,
    "children": {
        "run_training.setup": {
            "total": 0.17810710000000007,
            "count": 1,
            "self": 0.17810710000000007
        },
        "TrainerController.start_learning": {
            "total": 1878.3833454,
            "count": 1,
            "self": 3.0633863999955793,
            "children": {
                "TrainerController._reset_env": {
                    "total": 14.807657899999999,
                    "count": 1,
                    "self": 14.807657899999999
                },
                "TrainerController.advance": {
                    "total": 1860.4489599000044,
                    "count": 153015,
                    "self": 2.942359799985752,
                    "children": {
                        "env_step": {
                            "total": 1311.1355213000013,
                            "count": 153015,
                            "self": 1165.4678329000135,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 143.75261559998683,
                                    "count": 153015,
                                    "self": 8.729157799981465,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 135.02345780000536,
                                            "count": 152094,
                                            "self": 135.02345780000536
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.9150728000009956,
                                    "count": 153014,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1756.8161467000175,
                                            "count": 153014,
                                            "is_parallel": true,
                                            "self": 858.8211529000101,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0003764999999997798,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 9.969999999981383e-05,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00027679999999996596,
                                                            "count": 4,
                                                            "is_parallel": true,
                                                            "self": 0.00027679999999996596
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 897.9946173000073,
                                                    "count": 153014,
                                                    "is_parallel": true,
                                                    "self": 18.17851809999661,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 21.312626899981574,
                                                            "count": 153014,
                                                            "is_parallel": true,
                                                            "self": 21.312626899981574
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 813.0576715000414,
                                                            "count": 153014,
                                                            "is_parallel": true,
                                                            "self": 813.0576715000414
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 45.44580079998792,
                                                            "count": 153014,
                                                            "is_parallel": true,
                                                            "self": 14.10280029993661,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 31.34300050005131,
                                                                    "count": 612056,
                                                                    "is_parallel": true,
                                                                    "self": 31.34300050005131
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 546.3710788000172,
                            "count": 153014,
                            "self": 4.678670800005534,
                            "children": {
                                "process_trajectory": {
                                    "total": 86.90491400001207,
                                    "count": 153014,
                                    "self": 86.703717600012,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.20119640000007166,
                                            "count": 2,
                                            "self": 0.20119640000007166
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 454.78749399999964,
                                    "count": 642,
                                    "self": 284.23052420001125,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 170.5569697999884,
                                            "count": 12840,
                                            "self": 170.5569697999884
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.06334119999996801,
                    "count": 1,
                    "self": 0.01471639999999752,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.04862479999997049,
                            "count": 1,
                            "self": 0.04862479999997049
                        }
                    }
                }
            }
        }
    }
}